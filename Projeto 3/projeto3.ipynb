{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import find_best_hyperparameters as fbh\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar essa celula para utilizar o arquivo \"./Dmoz-Science.csv\"\n",
    "\n",
    "data = fbh.load_db(\"./Dmoz-Science.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar essa celula para utilizar o arquivo webkb-parsed.csv\n",
    "data = fbh.load_db(\"webkb-parsed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha  accuracy  f1_macro  f1_micro\n",
      "0    0.1  0.717500  0.711544  0.717500\n",
      "1    0.5  0.720000  0.716553  0.720000\n",
      "2    1.0  0.710833  0.709062  0.710833\n",
      "3    2.0  0.689167  0.689243  0.689167\n",
      "4    5.0  0.650000  0.649790  0.650000\n",
      "\n",
      "Melhor alpha encontrado: 0.5 com acurácia de 0.7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparams_df = fbh.greedy_search_MultinomialNB(data, [0.1, 0.5, 1.0, 2.0, 5.0])\n",
    "print(hyperparams_df)\n",
    "best_alpha_row = hyperparams_df.loc[hyperparams_df['accuracy'].idxmax()]\n",
    "best_alpha = best_alpha_row['alpha']\n",
    "best_accuracy = best_alpha_row['accuracy']\n",
    "print(f\"\\nMelhor alpha encontrado: {best_alpha} com acurácia de {best_accuracy:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "final_model = MultinomialNB(alpha=best_alpha)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "final_f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "final_f1_micro = f1_score(y_test, y_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas no conjunto de teste:\n",
      "Acurácia: 0.7200\n",
      "F1 Score (Macro): 0.7166\n",
      "F1 Score (Micro): 0.7200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nMétricas no conjunto de teste:\")\n",
    "print(f\"Acurácia: {final_accuracy:.4f}\")\n",
    "print(f\"F1 Score (Macro): {final_f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Micro): {final_f1_micro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dmoz-Science\n",
    "- O melhor hiperparâmetro encontrado foi alpha = 0.5, com base na maior acurácia no conjunto de validação. Esse valor representa um nível moderado de suavização, equilibrando a influência das frequências observadas no conjunto de treinamento e a necessidade de ajustar as probabilidades para lidar com categorias ou combinações de características raras ou ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'file_name': data.loc[y_test.index, 'file_name'],\n",
    "    'text': data.loc[y_test.index, 'text'],\n",
    "    'true_class': y_test,\n",
    "    'predicted_class': y_pred\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"./results_MultinomialNB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C  accuracy  f1_macro  f1_micro\n",
      "0    0.01  0.549167  0.541022  0.549167\n",
      "1    0.10  0.685833  0.681072  0.685833\n",
      "2    1.00  0.706667  0.702757  0.706667\n",
      "3   10.00  0.715000  0.711247  0.715000\n",
      "4  100.00  0.715833  0.713002  0.715833\n",
      "\n",
      "Melhor C encontrado: 100.0 com acurácia de 0.7158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparams_df = fbh.greedy_search_LogisticRegression(data, [0.01, 0.1, 1, 10, 100])\n",
    "print(hyperparams_df)\n",
    "best_row = hyperparams_df.loc[hyperparams_df['accuracy'].idxmax()]\n",
    "best_C = best_row['C']\n",
    "best_accuracy = best_row['accuracy']\n",
    "print(f\"\\nMelhor C encontrado: {best_C} com acurácia de {best_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(C=best_C, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "final_f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "final_f1_micro = f1_score(y_test, y_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados finais no conjunto de teste:\n",
      "Acurácia: 0.7158\n",
      "F1 Score (Macro): 0.7130\n",
      "F1 Score (Micro): 0.7158\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados finais no conjunto de teste:\")\n",
    "print(f\"Acurácia: {final_accuracy:.4f}\")\n",
    "print(f\"F1 Score (Macro): {final_f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Micro): {final_f1_micro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dmoz-Science\n",
    "- Para o LogisticRegression, a melhor acurácia foi obtida com C = 100, indicando que o conjunto de dados possui características que permitem ao modelo se beneficiar de uma regularização fraca. Isso sugere que o dataset é suficientemente grande, representativo e possui pouco ruído, permitindo que o modelo capture padrões mais complexos sem superestimar o efeito de regularização. Além disso, a presença de features altamente preditivas contribuiu para que o modelo, com coeficientes maiores, se ajustasse bem aos dados de treinamento, mantendo um bom desempenho no conjunto de validação. O resultado também demonstra que o modelo consegue equilibrar a redução do erro de treinamento com a capacidade de generalização para novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'file_name': data.loc[y_test.index, 'file_name'],\n",
    "    'text': data.loc[y_test.index, 'text'],\n",
    "    'true_class': y_test,\n",
    "    'predicted_class': y_pred\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"./results_LogisticRegression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C  accuracy  f1_macro  f1_micro\n",
      "0    0.01  0.720833  0.714070  0.720833\n",
      "1    0.10  0.723333  0.718956  0.723333\n",
      "2    1.00  0.716667  0.712776  0.716667\n",
      "3   10.00  0.705833  0.701577  0.705833\n",
      "4  100.00  0.706667  0.702845  0.706667\n",
      "\n",
      "Melhor C encontrado: 0.1 com acurácia de 0.7233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparams_df = fbh.greedy_search_LinearSVC(data, [0.01, 0.1, 1, 10, 100])\n",
    "print(hyperparams_df)\n",
    "best_row = hyperparams_df.loc[hyperparams_df['accuracy'].idxmax()]\n",
    "best_C = best_row['C']\n",
    "best_accuracy = best_row['accuracy']\n",
    "print(f\"\\nMelhor C encontrado: {best_C} com acurácia de {best_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearSVC(C=best_C, random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "final_f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "final_f1_micro = f1_score(y_test, y_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados finais no conjunto de teste:\n",
      "Acurácia: 0.7067\n",
      "F1 Score (Macro): 0.7028\n",
      "F1 Score (Micro): 0.7067\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados finais no conjunto de teste:\")\n",
    "print(f\"Acurácia: {final_accuracy:.4f}\")\n",
    "print(f\"F1 Score (Macro): {final_f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Micro): {final_f1_micro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dmoz-Science\n",
    "- Para o LinearSVC, a melhor acurácia foi obtida com C = 0.1 no LinearSVC, indicando que o conjunto de dados se beneficia de uma regularização mais forte. Isso sugere que o dataset pode conter alguma redundância ou ruído em suas features, e a penalização maior sobre os coeficientes contribuiu para reduzir o impacto de características menos relevantes ou correlacionadas. Com esse valor de C, o modelo conseguiu evitar o sobreajuste aos dados de treinamento, favorecendo uma generalização melhor para o conjunto de validação. Além disso, o ajuste com C = 0.1 reflete que a simplicidade do modelo, promovida pela regularização, foi mais eficaz para capturar os padrões relevantes nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'file_name': data.loc[y_test.index, 'file_name'],\n",
    "    'text': data.loc[y_test.index, 'text'],\n",
    "    'true_class': y_test,\n",
    "    'predicted_class': y_pred\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"./results_LinearSVC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression vs Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- LogisticRegression: Menos sensível a outliers, pois a log-loss dá mais peso a probabilidades globais.\n",
    "- LinearSVC: Mais sensível a outliers, já que hinge-loss tenta maximizar a margem e pode ser influenciada por pontos próximos ou no lado errado da margem.\n",
    "Estrutura do Dataset:\n",
    "- No LogisticRegression, classes bem separáveis podem se beneficiar de menor regularização (alto C), já no LinearSVC, essas mesmas classes podem sofrer com sobreajuste com alto C, preferindo maior regularização (baixo C) para priorizar a margem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
